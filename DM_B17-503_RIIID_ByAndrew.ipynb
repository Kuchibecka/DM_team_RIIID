{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-01-08T15:55:43.687407Z",
     "iopub.status.busy": "2021-01-08T15:55:43.686326Z",
     "iopub.status.idle": "2021-01-08T15:55:43.699118Z",
     "shell.execute_reply": "2021-01-08T15:55:43.698452Z"
    },
    "papermill": {
     "duration": 0.02752,
     "end_time": "2021-01-08T15:55:43.699252",
     "exception": false,
     "start_time": "2021-01-08T15:55:43.671732",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/riiid-test-answer-prediction/example_sample_submission.csv\n",
      "/kaggle/input/riiid-test-answer-prediction/example_test.csv\n",
      "/kaggle/input/riiid-test-answer-prediction/questions.csv\n",
      "/kaggle/input/riiid-test-answer-prediction/train.csv\n",
      "/kaggle/input/riiid-test-answer-prediction/lectures.csv\n",
      "/kaggle/input/riiid-test-answer-prediction/riiideducation/competition.cpython-37m-x86_64-linux-gnu.so\n",
      "/kaggle/input/riiid-test-answer-prediction/riiideducation/__init__.py\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2021-01-08T15:55:43.849981Z",
     "iopub.status.busy": "2021-01-08T15:55:43.750209Z",
     "iopub.status.idle": "2021-01-08T18:37:56.302968Z",
     "shell.execute_reply": "2021-01-08T18:37:56.303520Z"
    },
    "papermill": {
     "duration": 9732.598104,
     "end_time": "2021-01-08T18:37:56.303884",
     "exception": false,
     "start_time": "2021-01-08T15:55:43.705780",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19 34 34 ...  4  0  5]\n",
      "[16:00:26] WARNING: ../src/learner.cc:516: \n",
      "Parameters: { nthreads } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:00:27] WARNING: ../src/gbm/gbtree.cc:139: Tree method is automatically selected to be 'approx' for faster speed. To use old behavior (exact greedy algorithm on single machine), set tree_method to 'exact'.\n",
      "XGBClassifier(alpha=0.03, base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, eta=0.3, gamma=0,\n",
      "              gpu_id=-1, importance_type='gain', interaction_constraints='',\n",
      "              learning_rate=0.300000012, max_delta_step=0, max_depth=11,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "              n_estimators=175, n_jobs=0, nthreads=-1, num_parallel_tree=1,\n",
      "              random_state=0, reg_alpha=0.0299999993, reg_lambda=1,\n",
      "              scale_pos_weight=1, subsample=1, tree_method='approx',\n",
      "              validate_parameters=1, verbosity=None)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "from pandas.plotting import scatter_matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import gc\n",
    "\n",
    "pd.options.display.expand_frame_repr = False\n",
    "pd.set_option(\"display.max_columns\", 20)\n",
    "\n",
    "warnings.simplefilter('ignore')\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, learning_curve\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import riiideducation\n",
    "\n",
    "types = {\n",
    "    'row_id': 'int64',\n",
    "    'timestamp': 'int64',\n",
    "    'user_id': 'int32',\n",
    "    'content_id': 'int16',\n",
    "    'content_type_id': 'int8',\n",
    "    'task_container_id': 'int16',\n",
    "    'user_answer': 'int8',\n",
    "    'answered_correctly': 'int64',\n",
    "    'prior_question_elapsed_time': 'float32',\n",
    "    'prior_question_had_explanation': 'boolean'\n",
    "}\n",
    "\n",
    "train1 = pd.read_csv(\n",
    "    '/kaggle/input/riiid-test-answer-prediction/train.csv',\n",
    "    low_memory=False,\n",
    "    nrows=2.5 * (10 ** 6),\n",
    "    skiprows=0,\n",
    "    dtype=types\n",
    ")\n",
    "\n",
    "train2 = pd.read_csv(\n",
    "    '/kaggle/input/riiid-test-answer-prediction/train.csv',\n",
    "    low_memory=False,\n",
    "    nrows=2.5 * (10 ** 6),\n",
    "    skiprows=2 * (10 ** 7),\n",
    "    dtype=types\n",
    ")\n",
    "\n",
    "train3 = pd.read_csv(\n",
    "    '/kaggle/input/riiid-test-answer-prediction/train.csv',\n",
    "    low_memory=False,\n",
    "    nrows=2.5 * (10 ** 6),\n",
    "    skiprows=4 * (10 ** 7),\n",
    "    dtype=types\n",
    ")\n",
    "\n",
    "train4 = pd.read_csv(\n",
    "    '/kaggle/input/riiid-test-answer-prediction/train.csv',\n",
    "    low_memory=False,\n",
    "    nrows=2.5 * (10 ** 6),\n",
    "    skiprows=6 * (10 ** 7),\n",
    "    dtype=types\n",
    ")\n",
    "\n",
    "train5 = pd.read_csv(\n",
    "    '/kaggle/input/riiid-test-answer-prediction/train.csv',\n",
    "    low_memory=False,\n",
    "    nrows=2.5 * (10 ** 6),\n",
    "    skiprows=8 * (10 ** 7),\n",
    "    dtype=types\n",
    ")\n",
    "\n",
    "train2.columns = train1.columns\n",
    "train3.columns = train1.columns\n",
    "train4.columns = train1.columns\n",
    "train5.columns = train1.columns\n",
    "\n",
    "train = pd.concat([train1, train2, train3, train4, train5], axis=0, ignore_index=True)\n",
    "\n",
    "# --------------------------------FEATURE 4------------------------------------------------------\n",
    "grouped_by_container_df = train.groupby('task_container_id')\n",
    "container_df = grouped_by_container_df.agg(\n",
    "    {'answered_correctly': [\n",
    "        'mean',\n",
    "        'count'],\n",
    "        'content_type_id': ['sum']\n",
    "    }).copy()\n",
    "\n",
    "container_df.columns = [\n",
    "    'mean_container_acc',\n",
    "    'container_unit_count',\n",
    "    'lecs_in_container']\n",
    "container_df[\"lecs_in_container\"] = container_df[\"lecs_in_container\"].astype(int)\n",
    "container_df[\"lecs_to_qs\"] = container_df[\"lecs_in_container\"] / container_df[\"container_unit_count\"]\n",
    "\n",
    "container_df\n",
    "del [[train]]\n",
    "gc.collect()\n",
    "# --------------------------------FEATURE 4------------------------------------------------------\n",
    "\n",
    "# shift timstamp for 11 feature\n",
    "train_questions_only_df1 = train1[train1['answered_correctly'] != -1].copy()\n",
    "train_questions_only_df2 = train2[train2['answered_correctly'] != -1].copy()\n",
    "train_questions_only_df3 = train3[train3['answered_correctly'] != -1].copy()\n",
    "train_questions_only_df4 = train4[train4['answered_correctly'] != -1].copy()\n",
    "train_questions_only_df5 = train5[train5['answered_correctly'] != -1].copy()\n",
    "\n",
    "train_questions_only_df1['question_elapsed_time'] = train_questions_only_df1['prior_question_elapsed_time'].shift(-1)\n",
    "train_questions_only_df1['question_had_explanation'] = train_questions_only_df1['prior_question_had_explanation'].shift(-1)\n",
    "train_questions_only_df1['ts_shift'] = train_questions_only_df1['timestamp'].shift(+1)\n",
    "\n",
    "train_questions_only_df2['question_elapsed_time'] = train_questions_only_df2['prior_question_elapsed_time'].shift(-1)\n",
    "train_questions_only_df2['question_had_explanation'] = train_questions_only_df2['prior_question_had_explanation'].shift(-1)\n",
    "train_questions_only_df2['ts_shift'] = train_questions_only_df2['timestamp'].shift(+1)\n",
    "\n",
    "train_questions_only_df3['question_elapsed_time'] = train_questions_only_df3['prior_question_elapsed_time'].shift(-1)\n",
    "train_questions_only_df3['question_had_explanation'] = train_questions_only_df3['prior_question_had_explanation'].shift(-1)\n",
    "train_questions_only_df3['ts_shift'] = train_questions_only_df3['timestamp'].shift(+1)\n",
    "\n",
    "train_questions_only_df4['question_elapsed_time'] = train_questions_only_df4['prior_question_elapsed_time'].shift(-1)\n",
    "train_questions_only_df4['question_had_explanation'] = train_questions_only_df4['prior_question_had_explanation'].shift(-1)\n",
    "train_questions_only_df4['ts_shift'] = train_questions_only_df4['timestamp'].shift(+1)\n",
    "\n",
    "train_questions_only_df5['question_elapsed_time'] = train_questions_only_df5['prior_question_elapsed_time'].shift(-1)\n",
    "train_questions_only_df5['question_had_explanation'] = train_questions_only_df5['prior_question_had_explanation'].shift(-1)\n",
    "train_questions_only_df5['ts_shift'] = train_questions_only_df5['timestamp'].shift(+1)\n",
    "\n",
    "train_questions_only_df = pd.concat([train_questions_only_df1, train_questions_only_df2, train_questions_only_df3,\n",
    "                                     train_questions_only_df4, train_questions_only_df5], axis=0, ignore_index=True)\n",
    "train_questions_only_df = train_questions_only_df.drop(columns=['prior_question_elapsed_time',\n",
    "                                                                'prior_question_had_explanation'])\n",
    "\n",
    "del [[train_questions_only_df1]], [[train_questions_only_df2]], [[train_questions_only_df3]], \\\n",
    "    [[train_questions_only_df4]], [[train_questions_only_df5]]\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "train_lecs_only_df1 = train1.copy()\n",
    "train_lecs_only_df2 = train2.copy()\n",
    "train_lecs_only_df3 = train3.copy()\n",
    "train_lecs_only_df4 = train4.copy()\n",
    "train_lecs_only_df5 = train5.copy()\n",
    "\n",
    "train_lecs_only_df1['ts_shift'] = train_lecs_only_df1['timestamp'].shift(+1)\n",
    "train_lecs_only_df2['ts_shift'] = train_lecs_only_df2['timestamp'].shift(+1)\n",
    "train_lecs_only_df3['ts_shift'] = train_lecs_only_df3['timestamp'].shift(+1)\n",
    "train_lecs_only_df4['ts_shift'] = train_lecs_only_df4['timestamp'].shift(+1)\n",
    "train_lecs_only_df5['ts_shift'] = train_lecs_only_df5['timestamp'].shift(+1)\n",
    "\n",
    "train_lecs_only_df1 = train_lecs_only_df1[train_lecs_only_df1['content_type_id'] == 1].copy()\n",
    "train_lecs_only_df2 = train_lecs_only_df2[train_lecs_only_df2['content_type_id'] == 1].copy()\n",
    "train_lecs_only_df3 = train_lecs_only_df3[train_lecs_only_df3['content_type_id'] == 1].copy()\n",
    "train_lecs_only_df4 = train_lecs_only_df4[train_lecs_only_df4['content_type_id'] == 1].copy()\n",
    "train_lecs_only_df5 = train_lecs_only_df5[train_lecs_only_df5['content_type_id'] == 1].copy()\n",
    "\n",
    "train_lecs_only_df = pd.concat([train_lecs_only_df1, train_lecs_only_df2, train_lecs_only_df3,\n",
    "                                     train_lecs_only_df4, train_lecs_only_df5], axis=0, ignore_index=True)\n",
    "train_lecs_only_df = train_lecs_only_df.drop(columns=['prior_question_elapsed_time', 'prior_question_had_explanation'])\n",
    "\n",
    "del [[train_lecs_only_df1]], [[train_lecs_only_df2]], [[train_lecs_only_df3]], \\\n",
    "    [[train_lecs_only_df4]], [[train_lecs_only_df5]]\n",
    "gc.collect()\n",
    "\n",
    "del [[train1]], [[train2]], [[train3]], \\\n",
    "    [[train4]], [[train5]]\n",
    "gc.collect()\n",
    "\n",
    "questions = pd.read_csv('/kaggle/input/riiid-test-answer-prediction/questions.csv',\n",
    "                        dtype={'question_id': 'int16', 'part': 'int8', 'bundle_id': 'int16', 'tags': 'str'})\n",
    "lectures = pd.read_csv('/kaggle/input/riiid-test-answer-prediction/lectures.csv',\n",
    "                       dtype={'lectures_id': 'int16', 'tag': 'int16', 'part': 'int8', 'type_of': 'str'})\n",
    "ex_test = pd.read_csv('/kaggle/input/riiid-test-answer-prediction/example_test.csv')\n",
    "\n",
    "# --------------------------------FEATURE1------------------------------------------------------\n",
    "grouped_by_user_df = train_questions_only_df.groupby('user_id')\n",
    "\n",
    "user_ans_df = grouped_by_user_df.agg(\n",
    "    {\n",
    "        'answered_correctly': [\n",
    "            'mean',\n",
    "            'count']}\n",
    ").copy()\n",
    "\n",
    "user_ans_df.columns = [\n",
    "    'mean_user_accuracy',\n",
    "    'questions_answered'\n",
    "]\n",
    "\n",
    "user_ans_df\n",
    "# --------------------------------FEATURE1------------------------------------------------------\n",
    "\n",
    "# --------------------------------FEATURE 11.1------------------------------------------------------\n",
    "train_questions_only_df.loc[train_questions_only_df['timestamp'] == 0, 'timestamp'] = 0\n",
    "train_questions_only_df.loc[train_questions_only_df['timestamp'] == 0, 'ts_shift'] = 0\n",
    "train_questions_only_df['spent_time'] = train_questions_only_df['timestamp'] - train_questions_only_df['ts_shift'] \\\n",
    "                                        - train_questions_only_df['question_elapsed_time']\n",
    "train_questions_only_df.loc[train_questions_only_df['spent_time'] <= 0, 'spent_time'] = train_questions_only_df['spent_time'].mean()\n",
    "\n",
    "spend_user_qu_df = train_questions_only_df.groupby('user_id')\n",
    "spend_user_qu_df = spend_user_qu_df.agg({'spent_time': ['mean']}).copy()\n",
    "\n",
    "spend_user_qu_df.columns = ['mean_spend_user_qu']\n",
    "\n",
    "spend_user_qu_df[spend_user_qu_df['mean_spend_user_qu'] < 0]\n",
    "train_questions_only_df[train_questions_only_df['spent_time'] < 0]\n",
    "\n",
    "train_questions_only_df = train_questions_only_df.drop(columns=['spent_time', 'ts_shift', 'timestamp'])\n",
    "# --------------------------------FEATURE11.1------------------------------------------------------\n",
    "\n",
    "# --------------------------------FEATURE 11.2------------------------------------------------------\n",
    "train_lecs_only_df.loc[train_lecs_only_df['timestamp'] == 0, 'timestamp'] = 0\n",
    "train_lecs_only_df.loc[train_lecs_only_df['timestamp'] == 0, 'ts_shift'] = 0\n",
    "train_lecs_only_df['spent_time'] = train_lecs_only_df['timestamp'] - train_lecs_only_df['ts_shift']\n",
    "train_lecs_only_df.loc[train_lecs_only_df['timestamp'] == 0, 'spent_time'] = train_lecs_only_df['spent_time'].mean()\n",
    "\n",
    "spend_user_lec_df = train_lecs_only_df.groupby('user_id')\n",
    "spend_user_lec_df = spend_user_lec_df.agg({'spent_time': ['mean']}).copy()\n",
    "\n",
    "spend_user_lec_df.columns = ['mean_spend_user_lec']\n",
    "train_lecs_only_df[train_lecs_only_df['spent_time'] < 0]\n",
    "\n",
    "\n",
    "spend_user_lec_df\n",
    "\n",
    "del [[train_lecs_only_df]]\n",
    "gc.collect()\n",
    "\n",
    "# --------------------------------FEATURE11.2------------------------------------------------------\n",
    "\n",
    "# --------------------------------FEATURE5-6------------------------------------------------------\n",
    "# пока что просто среднее время на ответ без разгроничения на правильность\n",
    "user_ans_time_df = grouped_by_user_df.agg(\n",
    "    {\n",
    "        'question_elapsed_time': [\n",
    "            'mean']}\n",
    ").copy()\n",
    "\n",
    "user_ans_time_df.columns = ['mean_user_ans_time']\n",
    "\n",
    "user_ans_time_df\n",
    "\n",
    "del [[grouped_by_user_df]]\n",
    "gc.collect()\n",
    "# --------------------------------FEATURE5-6------------------------------------------------------\n",
    "\n",
    "# --------------------------------FEATURE 2------------------------------------------------------\n",
    "grouped_by_content_df = train_questions_only_df.groupby('content_id')\n",
    "content_answers_df = grouped_by_content_df.agg(\n",
    "    {\n",
    "        'answered_correctly': [\n",
    "            'mean',\n",
    "            'count'\n",
    "        ]\n",
    "    }\n",
    ").copy()\n",
    "\n",
    "content_answers_df.columns = [\n",
    "    'mean_que_accuracy',\n",
    "    'question_was_asked'\n",
    "]\n",
    "\n",
    "content_answers_df\n",
    "# --------------------------------FEATURE 2------------------------------------------------------\n",
    "\n",
    "\n",
    "# --------------------------------FEATURE ?------------------------------------------------------\n",
    "que_ans_time_df = grouped_by_content_df.agg(\n",
    "    {\n",
    "        'question_elapsed_time': [\n",
    "            'mean']}\n",
    ").copy()\n",
    "\n",
    "que_ans_time_df.columns = [\n",
    "    'mean_que_ans_time'\n",
    "]\n",
    "\n",
    "que_ans_time_df\n",
    "\n",
    "del [[grouped_by_content_df]]\n",
    "gc.collect()\n",
    "# --------------------------------FEATURE ?------------------------------------------------------\n",
    "\n",
    "train_questions_only_well = train_questions_only_df[train_questions_only_df['answered_correctly'] != 0].copy()\n",
    "\n",
    "# --------------------------------FEATURE 7-8------------------------------------------------------\n",
    "grouped_by_questions_well = train_questions_only_well.groupby('content_id')\n",
    "quest_well_df = grouped_by_questions_well.agg(\n",
    "    {\n",
    "        'question_elapsed_time': ['mean']\n",
    "    }).copy()\n",
    "quest_well_df.columns = ['mean_que_ans_time_well']\n",
    "\n",
    "quest_well_df[\"mean_que_ans_time_well\"] = quest_well_df[\"mean_que_ans_time_well\"].astype(int)\n",
    "\n",
    "quest_well_df\n",
    "\n",
    "del [[grouped_by_questions_well]]\n",
    "gc.collect()\n",
    "# --------------------------------FEATURE 7-8------------------------------------------------------\n",
    "\n",
    "# --------------------------------FEATURE 5-6------------------------------------------------------\n",
    "\n",
    "grouped_by_user_well = train_questions_only_well.groupby('user_id')\n",
    "user_well_df = grouped_by_user_well.agg(\n",
    "    {\n",
    "        'question_elapsed_time': ['mean']\n",
    "    }).copy()\n",
    "user_well_df.columns = ['mean_user_ans_time_well']\n",
    "user_well_df.fillna(max)\n",
    "# user_well_df[\"mean_prior_question_elapsed_time_user\"] = user_well_df[\"mean_prior_question_elapsed_time_user\"].astype(int)\n",
    "\n",
    "user_well_df\n",
    "\n",
    "del [[train_questions_only_well]]\n",
    "gc.collect()\n",
    "\n",
    "del [[grouped_by_user_well ]]\n",
    "gc.collect()\n",
    "# --------------------------------FEATURE 5-6------------------------------------------------------\n",
    "\n",
    "\n",
    "questions = questions.dropna()\n",
    "questions\n",
    "import re\n",
    "import sys\n",
    "\n",
    "# --------------------------------tags unitar------------------------------------------------------\n",
    "s = set()\n",
    "# dirt_list = questions[\"tags\"]\n",
    "dirt_list = questions[\"tags\"].str.split(\" \", expand=True)\n",
    "for merge in dirt_list:\n",
    "    ns = set(dirt_list[merge])\n",
    "    s.update(ns)\n",
    "\n",
    "s\n",
    "\n",
    "s = {i for i in s if pd.notna(i)}\n",
    "\n",
    "tag_df = pd.DataFrame(index=questions.value_counts(), columns=s)\n",
    "tag_df = tag_df.fillna(0)\n",
    "# tag_df.index = [i for i in range(13523)]\n",
    "tag_df\n",
    "\n",
    "buf = []\n",
    "tagg_df = pd.DataFrame(index=questions.value_counts())\n",
    "tagg_df.index = [i for i in range(len(questions.value_counts()))]\n",
    "# tagg_df.index = questions.index\n",
    "\n",
    "f = questions['tags']\n",
    "for i in s:\n",
    "    buf = []\n",
    "    for j in range(len(f.values)):\n",
    "        d = f.values[j].split(' ')\n",
    "        # print(d)\n",
    "        if i in d:\n",
    "            buf.append(1)\n",
    "        else:\n",
    "            buf.append(0)\n",
    "    df = pd.DataFrame(buf, columns=[i])\n",
    "    # print(df)\n",
    "    tagg_df = tagg_df.join(df)\n",
    "tagg_df\n",
    "\n",
    "# не трогать\n",
    "questions.index = [i for i in range(len(questions.value_counts()))]\n",
    "questions\n",
    "# --------------------------------tags unitar------------------------------------------------------\n",
    "\n",
    "# --------------------------------klusters tags------------------------------------------------------\n",
    "# todo: {  [TAGS feature]\n",
    "from gensim import corpora, models, matutils\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "'''X = tagg_df\n",
    "distorsions = []\n",
    "# %%\n",
    "for k in range(2, 150):\n",
    "    kmeans = KMeans(n_clusters=k)\n",
    "    kmeans.fit(X)\n",
    "    distorsions.append(kmeans.inertia_)\n",
    "# %%\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "plt.plot(range(2, 150), distorsions)\n",
    "plt.grid(True)\n",
    "plt.title('Elbow curve')\n",
    "plt.show()'''\n",
    "# %%\n",
    "# оптимальное число кластеров = 40\n",
    "\n",
    "kmeans = KMeans(n_clusters=40)\n",
    "km = kmeans.fit_predict(tagg_df)\n",
    "print(km)\n",
    "\n",
    "# %%\n",
    "\n",
    "tagg_df['tag_clust'] = km\n",
    "tagg_df\n",
    "\n",
    "# todo:  [TAGS feature] }\n",
    "# --------------------------------klusters tags------------------------------------------------------\n",
    "\n",
    "# --------------------------------adding tags to questions------------------------------------------------------\n",
    "tagg_df['index'] = tagg_df.index\n",
    "questions['index'] = questions.index\n",
    "questions = questions.merge(tagg_df, how='left', on='index')\n",
    "\n",
    "questions = questions.drop(columns=[i for i in list(questions.columns) if (i != 'question_id') & (i != 'tag_clust')])\n",
    "questions.rename(columns=lambda x: x.replace('question_id', 'content_id'), inplace=True)\n",
    "questions\n",
    "# --------------------------------adding tags to questions------------------------------------------------------\n",
    "\n",
    "# --------------------------------MERGE TRAIN------------------------------------------------------\n",
    "target = 'answered_correctly'\n",
    "# merge all features in one df\n",
    "train_questions_only_df = train_questions_only_df.merge(user_ans_df, how='left', on='user_id')\n",
    "\n",
    "train_questions_only_df = train_questions_only_df.merge(content_answers_df, how='left', on='content_id')\n",
    "\n",
    "train_questions_only_df = train_questions_only_df.merge(container_df, how='left', on='task_container_id')\n",
    "\n",
    "train_questions_only_df = train_questions_only_df.merge(user_ans_time_df, how='left', on='user_id')\n",
    "\n",
    "train_questions_only_df = train_questions_only_df.merge(que_ans_time_df, how='left', on='content_id')\n",
    "\n",
    "train_questions_only_df = train_questions_only_df.merge(quest_well_df, how='left', on='content_id')\n",
    "\n",
    "train_questions_only_df = train_questions_only_df.merge(user_well_df, how='left', on='user_id')\n",
    "\n",
    "train_questions_only_df = train_questions_only_df.merge(questions, how='left', on='content_id')\n",
    "\n",
    "train_questions_only_df = train_questions_only_df.merge(spend_user_lec_df, how='left', on='user_id')\n",
    "\n",
    "train_questions_only_df = train_questions_only_df.merge(spend_user_qu_df, how='left', on='user_id')\n",
    "\n",
    "train_questions_only_df\n",
    "# --------------------------------MERGE TRAIN------------------------------------------------------\n",
    "\n",
    "# --------------------------------CLEANING------------------------------------------------------\n",
    "train_questions_only_df['question_had_explanation'] = train_questions_only_df['question_had_explanation'].fillna(value=False).astype(bool)\n",
    "train_questions_only_df = train_questions_only_df.fillna(train_questions_only_df.mean())\n",
    "\n",
    "col_to_drop = ['row_id', 'content_type_id', 'task_container_id', 'user_answer']\n",
    "train_questions_only_df = train_questions_only_df.drop(columns=col_to_drop)\n",
    "\n",
    "train_questions_only_df\n",
    "gc.collect()\n",
    "# --------------------------------CLEANING------------------------------------------------------\n",
    "\n",
    "# --------------------------------PREPARE FOR TRAIN------------------------------------------------------\n",
    "features = ['user_id', 'content_id', 'question_elapsed_time',\n",
    "            'question_had_explanation', 'mean_user_accuracy', 'questions_answered',\n",
    "            'mean_que_accuracy', 'question_was_asked', 'mean_container_acc',\n",
    "            'container_unit_count', 'lecs_in_container', 'lecs_to_qs',\n",
    "            'mean_user_ans_time', 'mean_que_ans_time', 'mean_que_ans_time_well',\n",
    "            'mean_user_ans_time_well', 'tag_clust', 'mean_spend_user_lec', 'mean_spend_user_qu']\n",
    "\n",
    "features\n",
    "\n",
    "train_questions_only_df['question_had_explanation'] = train_questions_only_df['question_had_explanation'].astype(bool)\n",
    "\n",
    "train_df = train_questions_only_df[features].copy()\n",
    "y_train = train_questions_only_df[target].copy()\n",
    "\n",
    "del [[train_questions_only_df]]\n",
    "gc.collect()\n",
    "\n",
    "tr_mean = train_df.mean()\n",
    "\n",
    "# --------------------------------PREPARE FOR TRAIN------------------------------------------------------\n",
    "\n",
    "# --------------------------------XGBOOST------------------------------------------------------\n",
    "import xgboost\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "XGBmodel = xgboost.XGBClassifier(eta=0.3, max_depth=11, alpha=0.03, n_estimators=175, nthreads=-1)\n",
    "\n",
    "XGBmodel.fit(train_df, y_train)\n",
    "# %%\n",
    "print(XGBmodel)\n",
    "\n",
    "del [[train_df]]\n",
    "del [[y_train]]\n",
    "gc.collect()\n",
    "# --------------------------------XGBOOST------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-08T18:37:56.328937Z",
     "iopub.status.busy": "2021-01-08T18:37:56.325454Z",
     "iopub.status.idle": "2021-01-08T18:37:56.332565Z",
     "shell.execute_reply": "2021-01-08T18:37:56.331849Z"
    },
    "papermill": {
     "duration": 0.020778,
     "end_time": "2021-01-08T18:37:56.332735",
     "exception": false,
     "start_time": "2021-01-08T18:37:56.311957",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## SUBMISSION\n",
    "env = riiideducation.make_env()\n",
    "iter_test = env.iter_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-08T18:37:56.371989Z",
     "iopub.status.busy": "2021-01-08T18:37:56.371232Z",
     "iopub.status.idle": "2021-01-08T18:37:57.371574Z",
     "shell.execute_reply": "2021-01-08T18:37:57.370502Z"
    },
    "papermill": {
     "duration": 1.030629,
     "end_time": "2021-01-08T18:37:57.371795",
     "exception": false,
     "start_time": "2021-01-08T18:37:56.341166",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for (test_df, sample_prediction_df) in iter_test:\n",
    "    # merge\n",
    "    test_df['question_elapsed_time'] = test_df['prior_question_elapsed_time'].shift(-1)\n",
    "    test_df['question_had_explanation'] = test_df['prior_question_had_explanation'].shift(-1)\n",
    "        \n",
    "    test_df = test_df.merge(user_ans_df, how='left', on='user_id')\n",
    "    \n",
    "    test_df = test_df.merge(content_answers_df, how='left', on='content_id')\n",
    "    \n",
    "    test_df = test_df.merge(container_df, how='left', on='task_container_id')\n",
    "    \n",
    "    test_df = test_df.merge(user_ans_time_df, how='left', on='user_id')\n",
    "    \n",
    "    test_df = test_df.merge(que_ans_time_df, how='left', on='content_id')\n",
    "    \n",
    "    test_df = test_df.merge(quest_well_df, how='left', on='content_id')\n",
    "    \n",
    "    test_df = test_df.merge(user_well_df, how='left', on='user_id')\n",
    "    \n",
    "    test_df = test_df.merge(questions, how='left', on='content_id')\n",
    "    \n",
    "    test_df = test_df.merge(spend_user_lec_df, how='left', on='user_id')\n",
    "    \n",
    "    test_df = test_df.merge(spend_user_qu_df, how='left', on='user_id')\n",
    "        \n",
    "    test_df['question_had_explanation'] = test_df['question_had_explanation'].fillna(value=False).astype(bool)\n",
    "    test_df.fillna(tr_mean, inplace = True)\n",
    "        \n",
    "    \n",
    "    # preds\n",
    "    test_df['answered_correctly'] = XGBmodel.predict_proba(test_df[features])[:, 1]\n",
    "    cols_to_submission = ['row_id', 'answered_correctly', 'group_num']\n",
    "    env.predict(test_df.loc[test_df['content_type_id'] == 0, ['row_id', 'answered_correctly']])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 9739.27445,
   "end_time": "2021-01-08T18:37:57.522026",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-01-08T15:55:38.247576",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
